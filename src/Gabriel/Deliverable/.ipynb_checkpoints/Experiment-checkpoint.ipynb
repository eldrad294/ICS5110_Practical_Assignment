{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Module imports\n",
    "import seaborn as sns\n",
    "from pandas import DataFrame, concat, Series\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'EEGEyeState.csv'\n",
    "lag = 0\n",
    "df = pd.read_csv(path)\n",
    "df_values = df.values\n",
    "df_values_count = len(df_values)\n",
    "df_headers = df.columns\n",
    "df_header_count = len(df_headers)\n",
    "print('DF size before outlier removal: ' + str(df_values_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Representation\n",
    "\n",
    "### Box Plot EEG Eye State data set representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot Box Plots\n",
    "def plotBoxPlots(data, arrLabels, titleSuffix):\n",
    "    fig = plt.figure()\n",
    "    fig.set_figwidth(30)\n",
    "    fig.set_figheight(30)\n",
    "\n",
    "    ax1 = fig.add_subplot(1, 1, 1)\n",
    "    ax1.set_title('Feature range: full - ' + titleSuffix)\n",
    "    suppress = ax1.boxplot(data\n",
    "                           , sym='b.'\n",
    "                           , vert=False\n",
    "                           , whis='range'\n",
    "                           , labels=arrLabels\n",
    "                           , meanline=True\n",
    "                           , showbox=True\n",
    "                           , showfliers=True\n",
    "                           )\n",
    "    plt.show()\n",
    "    #\n",
    "    fig = plt.figure()\n",
    "    fig.set_figwidth(30)\n",
    "    fig.set_figheight(30)\n",
    "    ax2 = fig.add_subplot(1, 1, 1)\n",
    "    ax2.set_title('Feature range: [5%, 95%] - ' + titleSuffix)\n",
    "    suppress = ax2.boxplot(data\n",
    "                           , sym='b.'\n",
    "                           , vert=False\n",
    "                           , whis=[5, 95]\n",
    "                           , labels=arrLabels\n",
    "                           , meanline=True\n",
    "                           , showbox=True\n",
    "                           , showfliers=False\n",
    "                           )\n",
    "    plt.show()\n",
    "#\n",
    "# Plotting Box Plots\n",
    "plotBoxPlots(df_values[:,0:df_header_count], df_headers, 'Extreme outliers excluded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter Plot representation of the EEG Eye State data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "# Red = EyeClosed, Blue = EyeOpen\n",
    "Image(filename=\"Images/Scatter plot ['AF4'] vs ['P7'] Raw.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "# Red = EyeClosed, Blue = EyeOpen\n",
    "Image(filename=\"Images/Scatter plot ['F8'] vs ['AF3'] Raw.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "# Red = EyeClosed, Blue = EyeOpen\n",
    "Image(filename=\"Images/Scatter plot ['F8'] vs ['P8'] Raw.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "# Red = EyeClosed, Blue = EyeOpen\n",
    "Image(filename=\"Images/Scatter plot ['FC'] vs ['AF3'] Raw.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "# Red = EyeClosed, Blue = EyeOpen\n",
    "Image(filename=\"Images/Scatter plot ['FC'] vs ['P8'] Raw.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "# Red = EyeClosed, Blue = EyeOpen\n",
    "Image(filename=\"Images/Scatter plot ['O1'] vs ['FC'] Raw.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Representation\n",
    "\n",
    "### Box Plots EEG Eye State data set excluding outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Removing outliers\n",
    "def get_outlier_indexes(df, df_col_count, outlier_value=5000):\n",
    "    \"\"\" Takes a dataframe and returns the position of any outliers \"\"\"\n",
    "    outLierIndexes = set()\n",
    "    upperLimit = outlier_value\n",
    "    for x in range(df_col_count):\n",
    "        df = np.array(df)\n",
    "        outLiers = np.where(df[:, x] > upperLimit)[0]\n",
    "        if len(outLiers) > 0:\n",
    "            [(outLierIndexes.add(outLiers[i])) for i in range(len(outLiers))]\n",
    "    #\n",
    "    outLierIndexes = list(outLierIndexes)\n",
    "    outLierIndexes.sort()\n",
    "    return outLierIndexes\n",
    "#\n",
    "outlier_indexes = get_outlier_indexes(df_values, df_header_count)\n",
    "print('Extreme outliers\\nTotal:   ', len(outlier_indexes), \\\n",
    "    '\\nIndexes: ', outlier_indexes)\n",
    "[(print(DataFrame(df).iloc[[outlier]])) for outlier in outlier_indexes]\n",
    "df_values_pruned = np.delete(df_values, outlier_indexes, 0)\n",
    "df_values_pruned_count = len(df_values_pruned)\n",
    "df_pruned = pd.DataFrame(data=df_values_pruned, columns=df_headers)\n",
    "#\n",
    "print('DF size after outlier removal: ' + str(df_values_pruned_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot Box Plots\n",
    "def plotBoxPlots(data, arrLabels, titleSuffix):\n",
    "    fig = plt.figure()\n",
    "    fig.set_figwidth(30)\n",
    "    fig.set_figheight(30)\n",
    "\n",
    "    ax1 = fig.add_subplot(1, 1, 1)\n",
    "    ax1.set_title('Feature range: full - ' + titleSuffix)\n",
    "    suppress = ax1.boxplot(data\n",
    "                           , sym='b.'\n",
    "                           , vert=False\n",
    "                           , whis='range'\n",
    "                           , labels=arrLabels\n",
    "                           , meanline=True\n",
    "                           , showbox=True\n",
    "                           , showfliers=True\n",
    "                           )\n",
    "    plt.show()\n",
    "    #\n",
    "    fig = plt.figure()\n",
    "    fig.set_figwidth(30)\n",
    "    fig.set_figheight(30)\n",
    "    ax2 = fig.add_subplot(1, 1, 1)\n",
    "    ax2.set_title('Feature range: [5%, 95%] - ' + titleSuffix)\n",
    "    suppress = ax2.boxplot(data\n",
    "                           , sym='b.'\n",
    "                           , vert=False\n",
    "                           , whis=[5, 95]\n",
    "                           , labels=arrLabels\n",
    "                           , meanline=True\n",
    "                           , showbox=True\n",
    "                           , showfliers=False\n",
    "                           )\n",
    "    plt.show()\n",
    "#\n",
    "# Plotting Box Plots\n",
    "eegDataNoOutLiers_y = df_pruned['eyeDetection']\n",
    "eegDataNoOutLiers_X = df_pruned.drop('eyeDetection', 1)\n",
    "plotBoxPlots(eegDataNoOutLiers_X.values[:,0:len(eegDataNoOutLiers_X.columns)], eegDataNoOutLiers_X.columns, 'Extreme outliers excluded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter Plot representation of the EEG Eye State data set (excluding outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "# Red = EyeClosed, Blue = EyeOpen\n",
    "Image(filename=\"Images/Scatter plot ['AF4'] vs ['P7'].png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Red = EyeClosed, Blue = EyeOpen\n",
    "Image(filename=\"Images/Scatter plot ['F8'] vs ['AF3'].png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Red = EyeClosed, Blue = EyeOpen\n",
    "Image(filename=\"Images/Scatter plot ['F8'] vs ['P8'].png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Red = EyeClosed, Blue = EyeOpen\n",
    "Image(filename=\"Images/Scatter plot ['FC'] vs ['AF3'].png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Red = EyeClosed, Blue = EyeOpen\n",
    "Image(filename=\"Images/Scatter plot ['FC'] vs ['P8'].png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Red = EyeClosed, Blue = EyeOpen\n",
    "Image(filename=\"Images/Scatter plot ['O1'] vs ['FC'].png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Analysis\n",
    "\n",
    "### EEG Eye State data set time shifting (lag set to 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Applying lag to timeseries data set, by shifting degree of n\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    \"\"\"\n",
    "    Frame a time series as a supervised learning dataset.\n",
    "    Arguments:\n",
    "        data: Sequence of observations as a list or NumPy array.\n",
    "        n_in: Number of lag observations as input (X).\n",
    "        n_out: Number of observations as output (y).\n",
    "        dropnan: Boolean whether or not to drop rows with NaN values.\n",
    "    Returns:\n",
    "        Pandas DataFrame of series framed for supervised learning.\n",
    "    \"\"\"\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "#\n",
    "# N-Step Univariate Forecasting Shift\n",
    "df_pruned_shifted = series_to_supervised(data=df_pruned, n_in=lag, n_out=1, dropnan=True)\n",
    "#\n",
    "# Removing any lag variables of var15(t-lag) (label)\n",
    "if lag > 0:\n",
    "    for i in range(1,lag+1):\n",
    "        df_pruned_shifted = df_pruned_shifted.drop('var15(t-' + str(i) + ')', 1)\n",
    "df_pruned_shifted_headers = df_pruned_shifted.columns\n",
    "df_pruned_shifted_header_count = len(df_pruned_shifted_headers)\n",
    "print(df_pruned_shifted_headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line plots of feature readings over time (117 seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# AF3 line graph\n",
    "Image(filename=\"Images/AF3.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# AF4 line graph\n",
    "Image(filename=\"Images/AF4.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# F8 line graph\n",
    "Image(filename=\"Images/F8.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FC line graph\n",
    "Image(filename=\"Images/FC.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# O1 line graph\n",
    "Image(filename=\"Images/O1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# P7 line graph\n",
    "Image(filename=\"Images/P7.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# P8 line graph\n",
    "Image(filename=\"Images/P8.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# eyeDetection line graph\n",
    "Image(filename=\"Images/eyeDetection.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection - Filter Methods\n",
    "\n",
    "###  Pearson Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot Pearson's Correlation Matrix for shifted_df\n",
    "eegDF = pd.DataFrame(data=df_pruned_shifted, columns=df_pruned_shifted_headers)\n",
    "#\n",
    "# Compute the correlation matrix\n",
    "corr = eegDF.corr()\n",
    "#\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "#\n",
    "# Set up the matplotlib figure\n",
    "fig = plt.figure()\n",
    "fig.set_figheight(20)\n",
    "fig.set_figwidth(20)\n",
    "#\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.set_title(\"Feature correlation matrix\")\n",
    "#\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(240, 20, as_cmap=True)\n",
    "#\n",
    "# Draw the heatmap\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=1.0, vmin=-1.0, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "plt.show()\n",
    "#\n",
    "# Store the upper triangle of the correlation matrix into an Excel sheet\n",
    "corrUpperTri = corr.where(mask)\n",
    "writer = pd.ExcelWriter('EEG_Shifted_Correlation_Matrix.xlsx')\n",
    "corrUpperTri.to_excel(writer, 'CorrelationMatrix')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pearson's Correlation Matrix\n",
    "Image(filename=\"Images/Correlation Matrix Excluding Outliers.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto Correlation Plot for time series analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Autocorrelation Plot\n",
    "series = Series.from_csv(path, header=0)\n",
    "print(series.values)\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "if lag == 0:\n",
    "    lag = None\n",
    "plot_acf(series, lags=lag)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Limited to lag 100\n",
    "plot_acf(series, lags=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Methods (Mutual Information Scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mutual_info_score\n",
    "import operator\n",
    "mi_scores = {}\n",
    "for column in df_pruned_shifted_headers:\n",
    "    if column != 'var15(t)':\n",
    "        mi_scores[column] = mutual_info_score(df_pruned_shifted[column], df_pruned_shifted['var15(t)'])\n",
    "print('Mutual Information: ')\n",
    "print(sorted(mi_scores.items(), key=operator.itemgetter(1), reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data normalization, and cross validation splits of 80/20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Cross-validating of dataset: Splitting dataset into sub samples for training and testing purposes\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_pruned_shifted_Y = df_pruned_shifted['var15(t)']\n",
    "df_pruned_shifted_X = df_pruned_shifted.drop('var15(t)', 1)\n",
    "#\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_pruned_shifted_X, df_pruned_shifted_Y, test_size=0.2, random_state=0)\n",
    "#\n",
    "# L2 Normalization\n",
    "from sklearn.preprocessing import normalize\n",
    "# X_train = normalize(X_train, norm='l2')\n",
    "# X_test = normalize(X_test, norm='l2')\n",
    "#\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "#\n",
    "print(X_train)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection - Wrapper Methods\n",
    "\n",
    "### Random Forest Feature Importance Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Feature importance ranked using RandomForest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=500)\n",
    "df_pruned_shifted_Y = df_pruned_shifted['var15(t)']\n",
    "df_pruned_shifted_X = df_pruned_shifted.drop('var15(t)', 1)\n",
    "#\n",
    "rf.fit(df_pruned_shifted_X, df_pruned_shifted_Y)\n",
    "feature_importances = pd.DataFrame(rf.feature_importances_,\n",
    "                                   index = df_pruned_shifted_X.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)\n",
    "print('Random Forest Classification For Feature Selection: ')\n",
    "print(feature_importances)\n",
    "#\n",
    "# Plot the feature importance of the forest\n",
    "fig = plt.figure()\n",
    "fig.set_figheight(20)\n",
    "fig.set_figwidth(20)\n",
    "plt.title(\"RandomForest Feature importance\")\n",
    "objects = list(feature_importances.axes[0])\n",
    "y_pos = np.arange(len(objects))\n",
    "feature_importance = np.array(feature_importances)\n",
    "plt.bar(y_pos, feature_importance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Feature Importance Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Feature importance ranked using Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier()\n",
    "gbc.fit(X_train, y_train)\n",
    "feature_importances = pd.DataFrame({'feature': df_pruned_shifted_X.columns, 'importance': np.round(gbc.feature_importances_, 6)})\n",
    "feature_importances = feature_importances.sort_values('importance', ascending=False).set_index('feature')\n",
    "#\n",
    "print(feature_importances)\n",
    "#\n",
    "# Plot the feature importance of the forest\n",
    "fig = plt.figure()\n",
    "fig.set_figheight(20)\n",
    "fig.set_figwidth(20)\n",
    "plt.title(\"Gradient Boosting Feature importance\")\n",
    "objects = list(feature_importances.axes[0])\n",
    "y_pos = np.arange(len(objects))\n",
    "feature_importance = np.array(feature_importances)\n",
    "plt.bar(y_pos, feature_importance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine Feature Importance Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature importance ranked by linear SVM\n",
    "from sklearn import svm\n",
    "#\n",
    "svm = svm.SVC(kernel='linear')\n",
    "svm.fit(df_pruned_shifted_X, df_pruned_shifted_Y)\n",
    "df_pruned_shifted_X_columns = df_pruned_shifted_X.columns\n",
    "feature_importances = pd.DataFrame(svm.coef_[0],\n",
    "                                   index = df_pruned_shifted_X.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)\n",
    "print('SVM Classification For Feature Selection: ')\n",
    "print(feature_importances)\n",
    "#\n",
    "# Plot the feature importance of the SVM\n",
    "fig = plt.figure()\n",
    "fig.set_figheight(20)\n",
    "fig.set_figwidth(20)\n",
    "plt.title(\"Feature importance (Ranked by SVM)\")\n",
    "objects = list(feature_importances.axes[0])\n",
    "y_pos = np.arange(len(objects))\n",
    "feature_importance = np.array(feature_importances)\n",
    "plt.bar(y_pos, feature_importance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "#\n",
    "class Scoring_Functions():\n",
    "    #\n",
    "    def __init__(self, y_pred, y_true):\n",
    "        self.y_pred = y_pred\n",
    "        self.y_true = y_true\n",
    "    #\n",
    "    def accuracy(self):\n",
    "        # http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score\n",
    "        return str(accuracy_score(self.y_true, self.y_pred) * 100) + \"%\"\n",
    "    #\n",
    "    def precision(self):\n",
    "        # http: // scikit - learn.org / stable / modules / generated / sklearn.metrics.precision_score.html  # sklearn.metrics.precision_score\n",
    "        return str(precision_score(self.y_true, self.y_pred, average='weighted')* 100) + '%'\n",
    "    #\n",
    "    def recall(self):\n",
    "        # http://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score\n",
    "        return str(recall_score(self.y_true, self.y_pred, average='weighted') * 100) + '%'\n",
    "    #\n",
    "    def f_measure(self):\n",
    "        # http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score\n",
    "        return str(f1_score(self.y_true, self.y_pred, average='weighted') * 100) + '%'\n",
    "    #\n",
    "    def scoring_results(self):\n",
    "        return \"Accuracy: \" + str(self.accuracy()) + \"\\nPrecision: \" + str(self.precision()) + \"\\nRecall: \" + str(self.recall()) + \"\\nFMeasure: \" + str(self.f_measure())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Feature Importance Ranking (considering feature combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Wrapper Method - Random Forest Feature Selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from numpy import sort\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "#\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "feature_importances = pd.DataFrame({'feature': df_pruned_shifted_X.columns, 'importance': np.round(rfc.feature_importances_, 6)})\n",
    "feature_importances = feature_importances.sort_values('importance', ascending=False).set_index('feature')\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "#\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "#\n",
    "# make predictions for test data and evaluate\n",
    "pred_y = model.predict(X_test)\n",
    "#\n",
    "# Testing Classifier Accuracy\n",
    "sf = Scoring_Functions(y_pred=pred_y, y_true=y_test)\n",
    "print(\"RFC Accuracy: \")\n",
    "print(sf.scoring_results())\n",
    "print('-------------------------')\n",
    "#\n",
    "# fit model using each importance as a threshold\n",
    "thresholds = sort(model.feature_importances_)\n",
    "for thresh in thresholds:\n",
    "    # selecting features using threshold\n",
    "    selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    "    select_train_x = selection.transform(X_train)\n",
    "    #\n",
    "    # training model\n",
    "    selection_model = RandomForestClassifier()\n",
    "    selection_model.fit(select_train_x, y_train)\n",
    "    #\n",
    "    # evaluating model\n",
    "    select_test_x = selection.transform(X_test)\n",
    "    pred_y = selection_model.predict(select_test_x)\n",
    "    sf = Scoring_Functions(y_pred=pred_y, y_true=y_test)\n",
    "    print('Threshold: ' + str(thresh))\n",
    "    print('Feature Count: ' + str(select_train_x.shape[1]))\n",
    "    print(sf.scoring_results())\n",
    "    print('-------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Feature Importance Ranking (considering feature combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "#\n",
    "# make predictions for test data and evaluate\n",
    "pred_y = model.predict(X_test)\n",
    "#\n",
    "# Testing Classifier Accuracy\n",
    "sf = Scoring_Functions(y_pred=pred_y, y_true=y_test)\n",
    "print(\"GBC Accuracy: \")\n",
    "print(sf.scoring_results())\n",
    "print('-------------------------')\n",
    "#\n",
    "# fit model using each importance as a threshold\n",
    "thresholds = sort(model.feature_importances_)\n",
    "for thresh in thresholds:\n",
    "    # selecting features using threshold\n",
    "    selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    "    select_train_x = selection.transform(X_train)\n",
    "    #\n",
    "    # training model\n",
    "    selection_model = GradientBoostingClassifier()\n",
    "    selection_model.fit(select_train_x, y_train)\n",
    "    #\n",
    "    # evaluating model\n",
    "    select_test_x = selection.transform(X_test)\n",
    "    pred_y = selection_model.predict(select_test_x)\n",
    "    sf = Scoring_Functions(y_pred=pred_y, y_true=y_test)\n",
    "    print('Threshold: ' + str(thresh))\n",
    "    print('Feature Count: ' + str(select_train_x.shape[1]))\n",
    "    print(sf.scoring_results())\n",
    "    print('-------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation\n",
    "\n",
    "### Logistic Regression (Using Grid Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Logistic Regression\n",
    "# Drop unwanted variables which decrease accuracy of overall prediction (as generated from RFC)\n",
    "df_pruned_shifted_X_temp = df_pruned_shifted_X.drop('var9(t)', 1)\n",
    "df_pruned_shifted_X_temp = df_pruned_shifted_X_temp.drop('var3(t)', 1)\n",
    "#\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_pruned_shifted_X_temp, df_pruned_shifted_Y, test_size=0.2, random_state=0)\n",
    "#\n",
    "# using a grid search to find optimum hyper parameter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'penalty': ('l1', 'l2'), 'C':[10,11,12,13],'intercept_scaling': [1.1,1.2,1.3], 'fit_intercept':(True,False)}\n",
    "clf = LogisticRegression()\n",
    "clf = GridSearchCV(clf, parameters, cv=2)\n",
    "print(clf)\n",
    "clf.fit(X_train,y_train)\n",
    "print(clf.best_params_)\n",
    "#\n",
    "penalty=clf.best_params_['penalty']\n",
    "C=clf.best_params_['C']\n",
    "intercept_scaling=clf.best_params_['intercept_scaling']\n",
    "fit_intercept=clf.best_params_['fit_intercept']\n",
    "print(penalty)\n",
    "print(C)\n",
    "print(intercept_scaling)\n",
    "print(fit_intercept)\n",
    "clf = LogisticRegression(penalty=penalty,C=C,intercept_scaling=intercept_scaling,fit_intercept=fit_intercept)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf)\n",
    "#\n",
    "# make predictions for test data and evaluate\n",
    "pred_y = clf.predict(X_test)\n",
    "#\n",
    "# Testing Classifier Accuracy\n",
    "sf = Scoring_Functions(y_pred=pred_y, y_true=y_test)\n",
    "print(\"Logistic Regression Accuracy: \")\n",
    "print(sf.scoring_results())\n",
    "print('-------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Discriminant Analysis Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Linear Discriminant Analysis\n",
    "# Drop unwanted variables which decrease accuracy of overall prediction (as generated from RFC)\n",
    "# ... No features were dropped for LDA, as tests showed that LDA achieved greatest accuracy with all features being input\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_pruned_shifted_X_temp, df_pruned_shifted_Y, test_size=0.2, random_state=0)\n",
    "#\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "clf.fit(X_train,y_train)\n",
    "#\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf)\n",
    "#\n",
    "# make predictions for test data and evaluate\n",
    "pred_y = clf.predict(X_test)\n",
    "#\n",
    "# Testing Classifier Accuracy\n",
    "sf = Scoring_Functions(y_pred=pred_y, y_true=y_test)\n",
    "print(\"LDA Accuracy: \")\n",
    "print(sf.scoring_results())\n",
    "print('-------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classification (Using Grid Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Random Forest Classification\n",
    "# Drop unwanted variables which decrease accuracy of overall prediction (as generated from RFC)\n",
    "df_pruned_shifted_X_temp = df_pruned_shifted_X.drop('var9(t)', 1)\n",
    "#\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_pruned_shifted_X_temp, df_pruned_shifted_Y, test_size=0.2, random_state=0)\n",
    "#\n",
    "#Random Forest Classification based on acquired feature analysis\n",
    "n_estimators = 12000\n",
    "max_features = 'sqrt'\n",
    "criterion = 'gini'\n",
    "clf = RandomForestClassifier(n_estimators=n_estimators, max_features=max_features, n_jobs=6)\n",
    "clf.fit(X_train, y_train)\n",
    "#\n",
    "print(clf)\n",
    "#\n",
    "# make predictions for test data and evaluate\n",
    "pred_y = clf.predict(X_test)\n",
    "#\n",
    "# Testing Classifier Accuracy\n",
    "sf = Scoring_Functions(y_pred=pred_y, y_true=y_test)\n",
    "print(\"Random Forest Accuracy: \")\n",
    "print(sf.scoring_results())\n",
    "print('-------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roc Curve (RandomForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "# Compute fpr, tpr, thresholds and roc auc\n",
    "fpr, tpr, thresholds = roc_curve(y_test, pred_y)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "# Plot ROC curve\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate or (1 - Specifity)')\n",
    "plt.ylabel('True Positive Rate or (Sensitivity)')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
