{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "testID = 0\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as mt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import plot_model\n",
    "\n",
    "# SkLearn\n",
    "import sklearn.preprocessing as SklPreProcessing\n",
    "import sklearn.metrics as SklMetrics\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scoring_Functions():\n",
    "    #\n",
    "    def __init__(self, y_pred, y_true):\n",
    "        self.y_pred = y_pred\n",
    "        self.y_true = y_true\n",
    "    #\n",
    "    def accuracy(self):\n",
    "        # http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score\n",
    "        return str(accuracy_score(self.y_true, self.y_pred) * 100) + \"%\"\n",
    "    #\n",
    "    def precision(self):\n",
    "        # http: // scikit - learn.org / stable / modules / generated / sklearn.metrics.precision_score.html  # sklearn.metrics.precision_score\n",
    "        return str(precision_score(self.y_true, self.y_pred, average='weighted')* 100) + '%'\n",
    "    #\n",
    "    def recall(self):\n",
    "        # http://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score\n",
    "        return str(recall_score(self.y_true, self.y_pred, average='weighted') * 100) + '%'\n",
    "    #\n",
    "    def f_measure(self):\n",
    "        # http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score\n",
    "        return str(f1_score(self.y_true, self.y_pred, average='weighted') * 100) + '%'\n",
    "    #\n",
    "    def scoring_results(self):\n",
    "        return \"Accuracy: \" + str(self.accuracy()) + \"\\nPrecision: \" + str(self.precision()) + \"\\nRecall: \" + str(self.recall()) + \"\\nFMeasure: \" + str(self.f_measure())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMPredictor:\n",
    "    ############################\n",
    "    # MetaData\n",
    "    __testID = None\n",
    "    __cmdCount = 0\n",
    "    __cmdHistory = ''\n",
    "    __resultsRootDir = 'results'\n",
    "    ############################\n",
    "    # Dataset info\n",
    "    __eegData = None\n",
    "    __eegHeader = None\n",
    "    __testDataIndex = 0\n",
    "    __trainDataFileName = None\n",
    "    __testDataFileName = None\n",
    "    ############################\n",
    "    # ML model info\n",
    "    __model = None\n",
    "    __trainTestMap = None\n",
    "    ############################\n",
    "   \n",
    "    def __init__(self, testID, trainFilename, testFilename):\n",
    "        self.__testID = str(testID).zfill(5)\n",
    "        self.__createTestResultsDir()\n",
    "        self.__trainDataFileName = trainFilename\n",
    "        self.__testDataFileName = testFilename\n",
    "        self.ResetState()\n",
    "        \n",
    "    def ResetState(self):\n",
    "        tmpFileName = ''\n",
    "        self.__cmdHistory = ''\n",
    "        self.__cmdCount = 0\n",
    "        self.__loadData()\n",
    "    \n",
    "    ###########################################################################\n",
    "    # Plot methods\n",
    "    def PlotFeatures(self, filePrefix=None, figWidth=20, figHeight=20):\n",
    "        self.__addToHistory('PlotFeatures_filePrefix:' + str(filePrefix))\n",
    "        fig = plt.figure()\n",
    "        fig.set_figwidth(figWidth)\n",
    "        fig.set_figheight(figHeight)\n",
    "        \n",
    "        featureCount = len(self.__eegHeader) - 1\n",
    "        idxSubplot = 0\n",
    "        \n",
    "        for itr in range(featureCount):\n",
    "            idxSubplot = idxSubplot + 1\n",
    "            currAx = fig.add_subplot(featureCount + 1, 1, idxSubplot)\n",
    "            currAx.grid()\n",
    "            currAx.plot(self.__eegData[:, itr])\n",
    "            currAx.set_title(self.__eegHeader[itr])\n",
    "        \n",
    "        idxSubplot = idxSubplot + 1\n",
    "        currAx = fig.add_subplot(featureCount + 1, 1, idxSubplot)\n",
    "        currAx.grid()\n",
    "        currAx.plot(self.__eegData[:, -1])\n",
    "        currAx.set_title(self.__eegHeader[-1])\n",
    "\n",
    "        if filePrefix is None:\n",
    "            plt.show()\n",
    "        else:\n",
    "            pathToFile = self.__resultsRootDir + \"/\" + self.__testID + \"/\" + filePrefix\n",
    "            plt.savefig(pathToFile)\n",
    "            \n",
    "    def PlotBoxPlots(self, filePrefix=None, figWidth=20, figHeight=20):\n",
    "        self.__addToHistory('PlotBoxPlots_filePrefix:' + str(filePrefix))\n",
    "        fig = plt.figure()\n",
    "        fig.set_figwidth(figWidth)\n",
    "        fig.set_figheight(figHeight)\n",
    "        \n",
    "        ax1 = fig.add_subplot(2, 1, 1)\n",
    "        ax1.set_title('Feature range: Full')\n",
    "        ax1.boxplot(self.__eegData[:, :-1]\n",
    "                    , sym='b.'\n",
    "                    , vert=False\n",
    "                    , whis='range'\n",
    "                    , labels=self.__eegHeader[:-1]\n",
    "                    , meanline=True\n",
    "                    , showbox=True\n",
    "                    , showfliers=True)\n",
    "        \n",
    "        ax2 = fig.add_subplot(2, 1, 2)\n",
    "        ax2.set_title('Feature range: [5%, 95%]')\n",
    "        ax2.boxplot(self.__eegData[:, :-1]\n",
    "                    , sym='b.'\n",
    "                    , vert=False\n",
    "                    , whis=[5, 95]\n",
    "                    , labels=self.__eegHeader[:-1]\n",
    "                    , meanline=True\n",
    "                    , showbox=True\n",
    "                    , showfliers=False)\n",
    "        \n",
    "        if filePrefix is not None:\n",
    "            pathToFile = self.__resultsRootDir + \"/\" + self.__testID + \"/\" + filePrefix\n",
    "            plt.savefig(pathToFile)\n",
    "            \n",
    "    def PlotMeanDistribution(self, filePrefix=None, figWidth=20, figHeight=20):\n",
    "        self.__addToHistory('PlotMeanDistribution_filePrefix:' + str(filePrefix))\n",
    "        idxEyeClosed = np.where(self.__eegData[:, -1] == 1)[0]\n",
    "        idxEyeOpened = np.where(self.__eegData[:, -1] == 0)[0]\n",
    "        \n",
    "        featureCount = len(self.__eegHeader) - 1\n",
    "        xTick = np.array(range(featureCount))\n",
    "        \n",
    "        fig = plt.figure()\n",
    "        fig.set_figwidth(figWidth)\n",
    "        fig.set_figheight(figHeight)\n",
    "\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "        ax.grid()\n",
    "        ax.set_title('Mean Distribution')\n",
    "        ax.set_xticklabels(self.__eegHeader[0:-1])\n",
    "        ax.set_xticks(xTick)\n",
    "\n",
    "        ax.plot(xTick, self.__eegData[idxEyeOpened][:, 0:featureCount].mean(axis=0), 'bo')\n",
    "        ax.plot(xTick, self.__eegData[idxEyeClosed][:, 0:featureCount].mean(axis=0), 'ro')\n",
    "        ax.plot(xTick, self.__eegData[:, 0:featureCount].mean(axis=0), 'go')\n",
    "\n",
    "        ax.legend(['Eye Open', 'Eye Closed', 'Both'])\n",
    "        \n",
    "        if filePrefix is not None:\n",
    "            pathToFile = self.__resultsRootDir + \"/\" + self.__testID + \"/\" + filePrefix\n",
    "            plt.savefig(pathToFile)\n",
    "\n",
    "    def PlotStdDevDistribution(self, filePrefix=None, figWidth=20, figHeight=20):\n",
    "        self.__addToHistory('PlotStdDevDistribution_filePrefix:' + str(filePrefix))\n",
    "        idxEyeClosed = np.where(self.__eegData[:, -1] == 1)[0]\n",
    "        idxEyeOpened = np.where(self.__eegData[:, -1] == 0)[0]\n",
    "        \n",
    "        featureCount = len(self.__eegHeader) - 1\n",
    "        xTick = np.array(range(featureCount))\n",
    "        \n",
    "        fig = plt.figure()\n",
    "        fig.set_figwidth(figWidth)\n",
    "        fig.set_figheight(figHeight)\n",
    "\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "        ax.grid()\n",
    "        ax.set_title('Standard Deviation Distribution')\n",
    "        ax.set_xticklabels(self.__eegHeader[0:-1])\n",
    "        ax.set_xticks(xTick)\n",
    "\n",
    "        ax.plot(xTick, self.__eegData[idxEyeOpened][:, 0:featureCount].std(axis=0), 'bo')\n",
    "        ax.plot(xTick, self.__eegData[idxEyeClosed][:, 0:featureCount].std(axis=0), 'ro')\n",
    "        ax.plot(xTick, self.__eegData[:, 0:featureCount].std(axis=0), 'go')\n",
    "\n",
    "        ax.legend(['Eye Open', 'Eye Closed', 'Both'])\n",
    "        \n",
    "        if filePrefix is not None:\n",
    "            pathToFile = self.__resultsRootDir + \"/\" + self.__testID + \"/\" + filePrefix\n",
    "            plt.savefig(pathToFile)\n",
    "            \n",
    "    def FeatureCorrelationMatrix(self, filePrefix=None, figWidth=20, figHeight=20):\n",
    "        self.__addToHistory('FeatureCorrelationMatrix_filePrefix:' + str(filePrefix))\n",
    "        # Compute the correlation matrix\n",
    "        corr = pd.DataFrame(data=self.__eegData[:, :-1], columns=list(self.__eegHeader[:-1])).corr()\n",
    "        \n",
    "        # Generate a mask for the upper triangle\n",
    "        mask = np.zeros_like(corr, dtype=np.bool)\n",
    "        mask[np.triu_indices_from(mask)] = True\n",
    "        \n",
    "        # Set up the matplotlib figure\n",
    "        fig = plt.figure()\n",
    "        fig.set_figwidth(figWidth)\n",
    "        fig.set_figheight(figHeight)\n",
    "        \n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "        ax.set_title(\"Feature correlation matrix\")\n",
    "        \n",
    "        # Generate a custom diverging colormap\n",
    "        cmap = sns.diverging_palette(240, 10, as_cmap=True)\n",
    "        \n",
    "        # Draw the heatmap\n",
    "        sns.heatmap(corr, mask=mask, cmap=cmap, vmax=1.0, vmin=-1.0, center=0,\n",
    "                    square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "        \n",
    "        if filePrefix is not None:\n",
    "            pathToFile = self.__resultsRootDir + \"/\" + self.__testID + \"/\" + filePrefix\n",
    "            plt.savefig(pathToFile)\n",
    "\n",
    "    ###########################################################################\n",
    "    # Getters\n",
    "    def GetFeatureNames(self):\n",
    "        return self.__eegHeader[:-1]\n",
    "    \n",
    "    def GetCmdHistory(self):\n",
    "        return self.__cmdHistory\n",
    "    ###########################################################################\n",
    "    # Dataset operations\n",
    "    def RemoveFeatures(self, indices):\n",
    "        assert isinstance(indices, list), 'Parameter must be a list'\n",
    "\n",
    "        self.__addToHistory('RemoveFeatures:' + ','.join(str(x) for x in indices))\n",
    "        self.__eegHeader = np.delete(self.__eegHeader, indices)\n",
    "        self.__eegData = np.delete(self.__eegData, indices, axis=1)\n",
    "    \n",
    "    def RemoveOutliers(self, upperLimit=None, lowerLimit=None):\n",
    "        outLierIndexes = set()\n",
    "        result = {}\n",
    "        result['upper'] = set()\n",
    "        result['lower'] = set()\n",
    "        \n",
    "        self.__addToHistory('RemoveOutliers_Upper:' + str(upperLimit)\n",
    "                            + '_Lower:' + str(lowerLimit))\n",
    "        featureCount = len(self.__eegHeader) - 1\n",
    "\n",
    "        if upperLimit is not None:\n",
    "            for itr in range(featureCount):\n",
    "                outLiers = np.where(self.__eegData[:, itr] > upperLimit)[0]\n",
    "                if len(outLiers) > 0:\n",
    "                    for i in xrange(len(outLiers)):\n",
    "                        result['upper'].add(outLiers[i])\n",
    "\n",
    "        if lowerLimit is not None:\n",
    "            for itr in range(featureCount):\n",
    "                outLiers = np.where(self.__eegData[:, itr] < lowerLimit)[0]\n",
    "                if len(outLiers) > 0:\n",
    "                    for i in xrange(len(outLiers)):\n",
    "                        result['lower'].add(outLiers[i])\n",
    "                        \n",
    "        deleteIndexes = list(result['upper'].union(result['lower']))\n",
    "        self.__eegData = np.delete(self.__eegData, deleteIndexes, axis=0)\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def NormalizeData(self, normFunc='MinMax'):\n",
    "        self.__addToHistory('NormalizeData_Func:' + normFunc)\n",
    "        \n",
    "        if normFunc == 'MinMax':\n",
    "            scaler = SklPreProcessing.MinMaxScaler(feature_range=(0, 1))\n",
    "            self.__eegData = scaler.fit_transform(self.__eegData)\n",
    "        else:\n",
    "            self.__eegData = normalize(self.__eegData, norm=normFunc)\n",
    "        \n",
    "    ###########################################################################\n",
    "    # Keras LSTM model\n",
    "    def CompileModel(self, lagCount, neuronCount, dropOut,\n",
    "                     modelArchitectureFilename,\n",
    "                     lstmStackCount=1, useLaggedOutput=True,\n",
    "                     lossFunc='mae', optimizerFunc='adam'):\n",
    "        assert lstmStackCount > 0, 'lstmStackCount must be > 0'\n",
    "        self.__addToHistory('CompileModel_Lag:' + str(lagCount)\n",
    "                            + '_NeuronCount:' + str(neuronCount)\n",
    "                            + '_DropOut:' + str(dropOut)\n",
    "                            + '_useLaggedOutput:' + str(useLaggedOutput)\n",
    "                            + '_LossFunc:' + str(lossFunc)\n",
    "                            + '_OptimizerFunc:' + str(optimizerFunc)\n",
    "                            + '_lstmStackCount:' + str(lstmStackCount))\n",
    "        \n",
    "#         supervisedDataset = self.__timeSeriesToSupervised(lagCount, useLaggedOutput)\n",
    "        featureCount = len(self.__eegHeader) - 1\n",
    "        \n",
    "#         values = supervisedDataset.values\n",
    "#         trainingSet = values[:self.__testDataIndex, :]\n",
    "#         testingSet = values[self.__testDataIndex:, :]\n",
    "\n",
    "        trainingSet = self.__eegData[:self.__testDataIndex, :]\n",
    "        testingSet = self.__eegData[self.__testDataIndex:, :]\n",
    "        \n",
    "        print testingSet.shape\n",
    "        \n",
    "#         pastInputCount = (featureCount + 1) * lagCount\n",
    "        pastInputCount = featureCount\n",
    "        self.__trainTestMap = {}\n",
    "\n",
    "        self.__trainTestMap['trainingSet_inFeatures'] = trainingSet[:, :pastInputCount]\n",
    "        self.__trainTestMap['trainingSet_outFeature'] = trainingSet[:, -1]\n",
    "        \n",
    "        self.__trainTestMap['testingSet_inFeatures'] = testingSet[:, :pastInputCount]\n",
    "        self.__trainTestMap['testingSet_outFeature'] = testingSet[:, -1]\n",
    "        \n",
    "        # Reshape input to be 3D [samples, timesteps, features]\n",
    "#         featureDimSize = (featureCount + 1)\n",
    "        featureDimSize = featureCount\n",
    "        \n",
    "        print self.__trainTestMap['trainingSet_inFeatures'].shape\n",
    "        \n",
    "        self.__trainTestMap['trainingSet_inFeatures_reShaped'] = self.__trainTestMap['trainingSet_inFeatures'].reshape(\n",
    "            (self.__trainTestMap['trainingSet_inFeatures'].shape[0], lagCount, featureDimSize))\n",
    "        \n",
    "        self.__trainTestMap['testingSet_inFeatures_reShaped'] = self.__trainTestMap['testingSet_inFeatures'].reshape(\n",
    "            (self.__trainTestMap['testingSet_inFeatures'].shape[0], lagCount, featureDimSize))\n",
    "        \n",
    "        # Design network\n",
    "        self.__model = Sequential()\n",
    "        \n",
    "        batch_size = 10000\n",
    "        self.__model.add(LSTM(4, batch_input_shape=(batch_size, 1, 14), stateful=True, return_sequences=True))\n",
    "        self.__model.add(LSTM(4, batch_input_shape=(batch_size, 1, 14), stateful=True))\n",
    "\n",
    "        self.__model.add(Dense(1))\n",
    "        self.__model.compile(loss=lossFunc, optimizer=optimizerFunc)\n",
    "        \n",
    "        # Visualize LSTM network\n",
    "        pathToFile = self.__resultsRootDir + \"/\" + self.__testID + \"/\" + modelArchitectureFilename\n",
    "        plot_model(self.__model, to_file=pathToFile, show_shapes=True)\n",
    "        \n",
    "    def FitModel(self, epochCount, batchSize,\n",
    "                 resultsFile,\n",
    "                 lossFuncFilePrefix=None,\n",
    "                 predictionFilePrefix=None,\n",
    "                 figWidth=20, figHeight=20, verbosity=2):\n",
    "        assert self.__model != None, 'Model not compiled'\n",
    "        \n",
    "        self.__addToHistory('FitModel_EpochCount:' + str(epochCount)\n",
    "                            + '_BatchSize:' + str(batchSize)\n",
    "                            + '_lossFuncFilePrefix:' + str(lossFuncFilePrefix)\n",
    "                            + '_predictionFilePrefix:' + str(predictionFilePrefix))\n",
    "        \n",
    "        # Fit model\n",
    "        start = timer()\n",
    "        loss = []\n",
    "\n",
    "        for i in range(100):\n",
    "            modelHistory = self.__model.fit(self.__trainTestMap['trainingSet_inFeatures_reShaped'],\n",
    "                                     self.__trainTestMap['trainingSet_outFeature'],\n",
    "                                     epochs=1, batch_size=1, verbose=2, shuffle=False)\n",
    "            self.__model.reset_states()\n",
    "\n",
    "            loss.extend(modelHistory.history['loss'])\n",
    "            \n",
    "#         history = self.__model.fit(self.__trainTestMap['trainingSet_inFeatures_reShaped'],\n",
    "#                                  self.__trainTestMap['trainingSet_outFeature'],\n",
    "#                                  epochs=epochCount,\n",
    "#                                  batch_size=batchSize,\n",
    "# #                                  validation_data=(\n",
    "# #                                      self.__trainTestMap['testingSet_inFeatures_reShaped'],\n",
    "# #                                      self.__trainTestMap['testingSet_outFeature']\n",
    "# #                                  ),\n",
    "#                                  verbose=verbosity, shuffle=False)\n",
    "        end = timer()\n",
    "        \n",
    "        fig = plt.figure()\n",
    "        fig.set_figwidth(figWidth)\n",
    "        fig.set_figheight(figHeight)\n",
    "\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "        ax.grid()\n",
    "        ax.set_title('Loss Function')\n",
    "        ax.plot(loss)\n",
    "#         ax.plot(history.history['loss'], label='train')\n",
    "#         ax.plot(history.history['val_loss'], label='test')\n",
    "        plt.legend(['train', 'test'])\n",
    "                    \n",
    "        if lossFuncFilePrefix is not None:\n",
    "            pathToFile = self.__resultsRootDir + \"/\" + self.__testID + \"/\" + lossFuncFilePrefix\n",
    "            plt.savefig(pathToFile)\n",
    "\n",
    "        testDataPrediction = self.__model.predict_classes(self.__trainTestMap['testingSet_inFeatures_reShaped'])\n",
    "        testDataPredictionRaw = self.__model.predict(self.__trainTestMap['testingSet_inFeatures_reShaped'])\n",
    "                \n",
    "        scoringMetrics = Scoring_Functions(testDataPrediction, self.__trainTestMap['testingSet_outFeature'])\n",
    "        results = scoringMetrics.scoring_results()\n",
    "        results += '\\n\\nExecution time: '\n",
    "        results += str(end - start)\n",
    "        results += 'secs'\n",
    "        self.__writeResultsToFile(resultsFile, results)\n",
    "        print 'Results:\\n' + results\n",
    "\n",
    "        fig = plt.figure()\n",
    "        fig.set_figwidth(figWidth)\n",
    "        fig.set_figheight(figHeight)\n",
    "        \n",
    "        ax1 = fig.add_subplot(3, 1, 1)\n",
    "        ax1.grid()\n",
    "        ax1.set_title('Expected')\n",
    "        ax1.plot(self.__trainTestMap['testingSet_outFeature'])\n",
    "\n",
    "        ax2 = fig.add_subplot(3, 1, 2)\n",
    "        ax2.grid()\n",
    "        ax2.set_title('Prediction - With rounding')\n",
    "        ax2.plot(testDataPrediction)\n",
    "\n",
    "        ax3 = fig.add_subplot(3, 1, 3)\n",
    "        ax3.grid()\n",
    "        ax3.set_title('Prediction - Without rounding')\n",
    "        ax3.plot(testDataPredictionRaw)\n",
    "\n",
    "        if predictionFilePrefix is not None:\n",
    "            pathToFile = self.__resultsRootDir + \"/\" + self.__testID + \"/\" + predictionFilePrefix\n",
    "            plt.savefig(pathToFile)\n",
    "\n",
    "        # Reset __model\n",
    "        self.__model = None\n",
    "        self.__trainTestMap = None\n",
    "    \n",
    "    ###########################################################################\n",
    "    # Private methods\n",
    "    def __createTestResultsDir(self):\n",
    "        dirName = \"%s/%s\" % (self.__resultsRootDir, self.__testID)\n",
    "        if os.path.exists(dirName):\n",
    "            shutil.rmtree(dirName)\n",
    "        os.makedirs(dirName)\n",
    "        \n",
    "    def __loadData(self):\n",
    "        self.__eegHeader = np.genfromtxt(self.__trainDataFileName, delimiter=',', max_rows=1, dtype=str)\n",
    "        self.__eegData = np.genfromtxt(self.__trainDataFileName, delimiter=',', skip_header=1)\n",
    "        testDataSet = np.genfromtxt(self.__testDataFileName, delimiter=',', skip_header=1)\n",
    "        \n",
    "        self.__testDataIndex = self.__eegData.shape[0]\n",
    "        self.__eegData = np.append(self.__eegData, testDataSet, axis=0)\n",
    "\n",
    "    def __timeSeriesToSupervised(self, lagCount, useLaggedOutput):\n",
    "        featureCount = len(self.__eegHeader) - 1\n",
    "\n",
    "        cols, names = list(), list()\n",
    "        dfInput = pd.DataFrame(self.__eegData[:, :-1])\n",
    "        dfOutput = pd.DataFrame(self.__eegData[:, -1])\n",
    "        \n",
    "        for i in range(lagCount, 0, -1):\n",
    "            cols.append(dfInput.shift(i))\n",
    "            if useLaggedOutput:\n",
    "                cols.append(dfOutput.shift(i))\n",
    "            else:\n",
    "                # Set the lagged output variable to a constant 0.5\n",
    "                tmp = len(dfOutput.shift(i))\n",
    "                cols.append(pd.DataFrame(np.ones(tmp) * 0.5))\n",
    "            \n",
    "            names += [('%s(t-%d)' % (self.__eegHeader[j], i)) for j in range(featureCount)]\n",
    "            names += [('%s(t-%d)' % (self.__eegHeader[-1], i))]\n",
    "\n",
    "        cols.append(dfInput)\n",
    "        cols.append(dfOutput)\n",
    "        names += [('%s(t)' % self.__eegHeader[j]) for j in range(featureCount)]\n",
    "        names += [('%s(t)' % self.__eegHeader[-1])]\n",
    "\n",
    "        agg = pd.concat(cols, axis=1)\n",
    "        agg.columns = names\n",
    "\n",
    "        # Drop rows containing NaN values\n",
    "        agg.dropna(inplace=True)\n",
    "        return agg\n",
    "    \n",
    "    def __addToHistory(self, newCmd):\n",
    "        tmpStr = ''\n",
    "        if self.__cmdCount > 0:\n",
    "            tmpStr += '\\n'\n",
    "            for itr in range(self.__cmdCount):\n",
    "                tmpStr += '+'\n",
    "                \n",
    "        tmpStr += newCmd\n",
    "        self.__cmdHistory += tmpStr\n",
    "        self.__cmdCount += 1\n",
    "        \n",
    "    def __writeResultsToFile(self, resFilename, results):\n",
    "        pathToResultsFile = self.__resultsRootDir + \"/\" + self.__testID + \"/\" + resFilename\n",
    "        resString = ''\n",
    "        \n",
    "        if os.path.exists(pathToResultsFile):\n",
    "            resString = '\\n\\n-----------------------------------------------------------------\\n'\n",
    "            fileMode = 'a' # Append\n",
    "        else:\n",
    "            fileMode = 'w' # Create\n",
    "        \n",
    "        text_file = open(pathToResultsFile, fileMode)\n",
    "        \n",
    "        resString += 'Results:\\n'\n",
    "        resString += results\n",
    "        resString += '\\n\\nCommand history:\\n----------------\\n'\n",
    "        resString += self.__cmdHistory        \n",
    "\n",
    "        text_file.write(resString)\n",
    "        text_file.close()\n",
    "    ###########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestID:  1\n",
      "(4480, 15)\n",
      "(10000, 14)\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (1, 1, 14) for Tensor u'lstm_101_input:0', which has shape '(10000, 1, 14)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-ad2e5656157e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m            \u001b[0;34m,\u001b[0m \u001b[0mlossFuncFilePrefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'01_lossFile'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m            \u001b[0;34m,\u001b[0m \u001b[0mpredictionFilePrefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'01_predictionFile'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m            , verbosity=2)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-83-afc9d8fc1ec5>\u001b[0m in \u001b[0;36mFitModel\u001b[0;34m(self, epochCount, batchSize, resultsFile, lossFuncFilePrefix, predictionFilePrefix, figWidth, figHeight, verbosity)\u001b[0m\n\u001b[1;32m    314\u001b[0m             modelHistory = self.__model.fit(self.__trainTestMap['trainingSet_inFeatures_reShaped'],\n\u001b[1;32m    315\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__trainTestMap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'trainingSet_outFeature'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                                      epochs=1, batch_size=1, verbose=2, shuffle=False)\n\u001b[0m\u001b[1;32m    317\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/niki/tensorflow/local/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/niki/tensorflow/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/home/niki/tensorflow/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/niki/tensorflow/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/niki/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/niki/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1094\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1097\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (1, 1, 14) for Tensor u'lstm_101_input:0', which has shape '(10000, 1, 14)'"
     ]
    }
   ],
   "source": [
    "testID = 1\n",
    "print \"TestID: \", testID\n",
    "\n",
    "resultsFilename = 'TestResults.txt'\n",
    "\n",
    "predictor = LSTMPredictor(testID\n",
    "                          , trainFilename='EEGEyeState_Training.arff.csv'\n",
    "                          , testFilename='EEGEyeState_Testing.arff.csv')\n",
    "\n",
    "\n",
    "res = predictor.RemoveOutliers(upperLimit=5000)\n",
    "predictor.NormalizeData()\n",
    "\n",
    "lagValue = 1\n",
    "predictor.CompileModel(lagCount=lagValue\n",
    "               , neuronCount=50\n",
    "               , dropOut=0.0\n",
    "               , useLaggedOutput=True\n",
    "               , modelArchitectureFilename='01_modelArchitecture'\n",
    "               , lstmStackCount=5)\n",
    "\n",
    "predictor.FitModel(epochCount=100\n",
    "           , batchSize=500\n",
    "           , resultsFile=resultsFilename\n",
    "           , lossFuncFilePrefix='01_lossFile'\n",
    "           , predictionFilePrefix='01_predictionFile'\n",
    "           , verbosity=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keraEnv",
   "language": "python",
   "name": "keraenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
